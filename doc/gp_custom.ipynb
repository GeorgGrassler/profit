{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from profit.sur.backend.gp_functions import invert, nll\n",
    "from profit.sur.backend.kernels import kern_sqexp\n",
    "from profit.util.halton import halton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x): return x*np.cos(10*x)\n",
    "\n",
    "# Custom function to build GP matrix\n",
    "def build_K(xa, xb, hyp, K):\n",
    "    for i in np.arange(len(xa)):\n",
    "        for j in np.arange(len(xb)):\n",
    "            K[i, j] = kern_sqexp(xa[i], xb[j], hyp[0])\n",
    "\n",
    "noise_train = 0.0\n",
    "\n",
    "ntrain = 6\n",
    "xtrain = halton(1, ntrain)\n",
    "ftrain = f(xtrain)\n",
    "ytrain = ftrain + noise_train*(np.random.rand(ntrain, 1) - 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GP regression with fixed kernel hyperparameters\n",
    "hyp = [0.5, 1e-6]  # l and sig_noise**2\n",
    "\n",
    "K = np.empty((ntrain, ntrain))   # train-train\n",
    "build_K(xtrain, xtrain, hyp, K)  # writes inside K\n",
    "Ky = K + hyp[-1]**2*np.eye(ntrain)\n",
    "Kyinv = invert(Ky, 4, 1e-6)       # using gp_functions.invert\n",
    "\n",
    "ntest = 20\n",
    "xtest = np.linspace(0, 1, ntest)\n",
    "ftest = f(xtest)\n",
    "\n",
    "Ks = np.empty((ntrain, ntest))  # train-test\n",
    "Kss = np.empty((ntest, ntest))  # test-test\n",
    "build_K(xtrain, xtest, hyp, Ks)\n",
    "build_K(xtest, xtest, hyp, Kss)\n",
    "\n",
    "fmean = Ks.T.dot(Kyinv.dot(ytrain)) # predictive mean\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(xtrain, ytrain, 'x')\n",
    "plt.plot(xtest, ftest, '-')\n",
    "plt.plot(xtest, fmean, '--')\n",
    "plt.legend(('training', 'reference', 'prediction'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Negative log likelihood over length scale\n",
    "ls = np.linspace(1e-3, 0.3, 50)\n",
    "nlls = np.array(\n",
    "    [nll([l, 1e-6], xtrain, ytrain, build_K=build_K) for l in ls]\n",
    "    ).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(ls, nlls)\n",
    "plt.xlabel('l')\n",
    "plt.ylabel('- log p(y|l)')\n",
    "plt.title('Negative log-likelihood')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "name": "python38264bitee8223ec65594bc885f48f30722f6205"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
